-- 0. Create a validation stream
-- 1. Group by key from find validate -- aggregation -> create a table, group by become a part of primary key 	
-- 2. Session Window 
-- 3. Rekey with a stream
-- 4. filter null values
-- 5. filter values count greater than 3
-- 6. Join with Order & set order to validated
-- 7. Push to orders`

SET 'auto.offset.reset'='earliest';



DROP STREAM IF EXISTS s_ov;
CREATE STREAM s_ov  (OrderValidation STRUCT <OrderValidationResult VARCHAR, OrderValidationType VARCHAR,orderId integer> )  WITH (KAFKA_TOPIC='order-validations', VALUE_FORMAT='JSON');  
-- Aggreate -> Create a table t_s_ot

-- |ORDERVALIDATION->{ORDERVALIDATIONRESULT=FAIL, ORDERVALIDATIONTYPE=ORDER_DETAILS_CHECK, ORDERID=29427}   
--1 
--DROP table IF EXISTS t_s_ov delete topic;
--CREATE TABLE t_s_ov  AS select ORDERVALIDATION->orderid as rowkey, as_value(ORDERVALIDATION->orderid),  count(*) as total  from s_ov  window tumbling (size 60 seconds)   where ORDERVALIDATION->ORDERVALIDATIONRESULT ='PASS'   group by ORDERVALIDATION->orderid emit changes;

-- 2.a
DROP STREAM IF EXISTS s_s_ov;
create stream s_s_ov as select ORDERVALIDATION->orderid as id from s_ov where  ORDERVALIDATION->ORDERVALIDATIONRESULT ='PASS'  emit changes;
-- 2.b
DROP table IF EXISTS t_s_s_ov;
CREATE TABLE t_s_s_ov  AS select id as rowkey, as_value(id) as id,  count(*) as total  from s_s_ov  window tumbling (size 60 seconds)   group by id emit changes;

select * from t_s_s_ov emit changes limit 2;
-- Need to remove windowing so creating a stream

DROP STREAM IF EXISTS s_t_s_s_ov;
CREATE STREAM s_t_s_s_ov  ( id integer, total integer )  WITH (KAFKA_TOPIC='T_S_S_OV',VALUE_FORMAT='JSON') ;
select * from s_t_s_s_ov emit changes limit 2;
-- not working
-- CREATE STREAM s_t_s_s_ov  (oid integer key, total integer )  WITH (KAFKA_TOPIC='T_S_S_OV',VALUE_FORMAT='JSON') ;


-- Create Stream of Orders topic as s_o without key
DROP STREAM IF EXISTS s_o;
CREATE stream s_o ( id integer, quantity integer,price integer,customerId integer,OrderState varchar, product varchar )  WITH (KAFKA_TOPIC='orders', VALUE_FORMAT='JSON');
-- Create Stream of Order-validations topic  s_ot
select * from s_o emit changes  limit 10;

-- Create stream to orders topic to push the update with order status -> VALIDATED
DROP STREAM IF EXISTS s_o_key;
CREATE stream s_o_key (id_key integer key,id integer, quantity integer,price integer,customerId integer,OrderState varchar, product varchar )  WITH (KAFKA_TOPIC='orders', VALUE_FORMAT='JSON');
-- Create Stream of Order-validations topic  s_ot
select * from s_o_key emit changes  limit 10;

  
-- Join two streams requires within timeframe
-- 1. Filter orders which has status CREATED
-- 2. Filter order-aggregation with total count = 3
-- 3. join both using orderid
-- 4. insert into a new stream from orders topic with order as a key and id. 
insert into s_o_key select o.id as id_key, as_value(o.id) as id, o.quantity as quantity,o.price as price,o.customerId as customerId, 'VALIDATED' as OrderState,o.product as product  from s_o o  left join  s_t_s_s_ov ot  within 1 HOURS  on o.id = ot.id where ot.total>=3 and o.OrderState = 'CREATED'   emit changes;

-- Learning 
-- > insert into s_t select o.id as id, o.quantity as quantity,o.price as price,o.customerId as customerId, 'VALIDATED' as ORDERSTATE,o.product as product  from s_o o  left join  s_t_s_s_ov ot  within 1 HOURS  on o.id = ot.id where ot.total>=3 and o.ORDERSTATE = 'CREATED'   emit changes ;
--Exception while preparing statement: INSERT INTO can only be used to insert into a stream. S_T is a table.



-- Send email

--create stream s_o_key as select * from s_o where   OrderState='VALIDATED' emit changes;

DROP STREAM IF EXISTS s_p;
CREATE stream s_p (id integer, amount integer,ccy varchar,orderId integer  )  WITH (KAFKA_TOPIC='payments', VALUE_FORMAT='JSON');


-- Rekey payments to join both orders and the payment together
DROP STREAM IF EXISTS s_p_rekey delete topic;
CREATE STREAM s_p_rekey (orderId INT key, ccy varchar,amount double)
    WITH (kafka_topic='payments_rekey',
          partitions=1,
          value_format='json'); 

insert into s_p_rekey   SELECT orderId,ccy,cast(amount as double) as amount
    FROM s_p
    PARTITION BY orderId;
select * from s_p_rekey emit changes;



DROP STREAM IF EXISTS s_c;
CREATE stream s_c (id integer , firstName varchar, lastName varchar, email varchar, address varchar, level varchar )  WITH (KAFKA_TOPIC='customers', VALUE_FORMAT='JSON');
select * from s_c emit changes;

-- create a join of order and the payment

DROP STREAM IF EXISTS s_j_op;
CREATE stream s_j_op as select o.id as id, o.quantity as quantity, o.price as amount, o.customerId as customerId, o.product as product, p.ccy as ccy  from s_o_key o join s_p_rekey p within 1 HOURS on o.id=p.orderId  emit changes;
select  id as orderId, c.FIRSTNAME as firstName  from s_j_op emit changes;

 -- select * from s_j_op jop join s_c c within 1 HOURS on jop.customerId=c.id emit changes limit 1;
 
-- Create a topic to generate an email message for microservice 
DROP STREAM IF EXISTS s_e;
create stream s_e (orderId integer key, email varchar, message varchar)  WITH (KAFKA_TOPIC='emails', VALUE_FORMAT='JSON' , PARTITIONS=1);
-- Join order_payment with customer 
insert into s_e  select  jop.id as orderId, c.email as email, (
'Hi ' + c.FIRSTNAME + ', Thanks for the order for the item ' + jop.product + ' with quantity '+ cast(jop.quantity as varchar) + '. The payment of the amount '+ jop.ccy + ' '+ cast(jop.amount as varchar) +' has received successfully. We will ship your order at ' + c.ADDRESS + ' within next 20 working days!') as message
from s_j_op jop join s_c c within 1 HOURS on jop.customerId=c.id   PARTITION BY jop.id emit changes;



select * from s_e emit changes;




current landloard name , contact , address
previous landloard name , contact , address

current visa copy
passport or DL copy 

2 references

s_j_op

select o.id as id, o.quantity as quantity, o.price as amount, o.customerId as customerId, o.product as product, p.ccy as ccy  from s_o_key o join s_p_rekey p within 1 HOURS on o.id=p.orderId  emit changes limit 1;


select op.* from (select * from s_o_key o join s_p_rekey p within 1 HOURS on o.id=p.orderId emit changes) op emit changes;

select op.* from (select * from s_o_key o join s_p_rekey p within 1 HOURS on o.id=p.orderId ) op join s_c within 1 HOURS on op.O_customerId=c.id  emit changes;
select op.* from (select * from s_o_key o join s_p_rekey p within 1 HOURS on o.id=p.orderId emit changes) op join s_c within 1 HOURS on op.O_customerId=c.id  emit changes;



 log.warn("Sending email: \nCustomer:{}\nOrder:{}\nPayment{}", details.customer, details.order, details.payment);

-- Create Stream of Order-validations topic  s_ot
select * from s_p emit changes  limit 10;
id: vars.order.pId,
amount: vars.order.price,
ccy:  vars.order.ccy,
orderId: vars.order.id,


kafka-topics.sh --zookeeper 127.0.0.1:2181 --alter --topic orders --config retention.ms=1000


-- cleanup 
terminate INSERTQUERY_281;
DROP STREAM IF EXISTS s_t_s_s_ov;

terminate CTAS_T_S_S_OV_279;
DROP STREAM IF EXISTS t_s_s_ov;

terminate CSAS_S_S_OV_259;
DROP STREAM IF EXISTS s_s_ov;

DROP STREAM IF EXISTS s_o delete topic;
DROP STREAM IF EXISTS s_ov delete topic;


CLOUD400

-- ./kafka-configs --zookeeper localhost:2181 --alter  --config retention.ms=1000 --topic products